{"cells":[{"cell_type":"markdown","id":"b4ae5707-109f-4cd6-8168-88cac0179d6b","metadata":{},"source":["![dvd_image](dvd_image.jpg)\n","\n","A DVD rental company needs your help! They want to figure out how many days a customer will rent a DVD for based on some features and has approached you for help. They want you to try out some regression models which will help predict the number of days a customer will rent a DVD for. The company wants a model which yeilds a MSE of 3 or less on a test set. The model you make will help the company become more efficient inventory planning.\n","\n","The data they provided is in the csv file `rental_info.csv`. It has the following features:\n","- `\"rental_date\"`: The date (and time) the customer rents the DVD.\n","- `\"return_date\"`: The date (and time) the customer returns the DVD.\n","- `\"amount\"`: The amount paid by the customer for renting the DVD.\n","- `\"amount_2\"`: The square of `\"amount\"`.\n","- `\"rental_rate\"`: The rate at which the DVD is rented for.\n","- `\"rental_rate_2\"`: The square of `\"rental_rate\"`.\n","- `\"release_year\"`: The year the movie being rented was released.\n","- `\"length\"`: Lenght of the movie being rented, in minuites.\n","- `\"length_2\"`: The square of `\"length\"`.\n","- `\"replacement_cost\"`: The amount it will cost the company to replace the DVD.\n","- `\"special_features\"`: Any special features, for example trailers/deleted scenes that the DVD also has.\n","- `\"NC-17\"`, `\"PG\"`, `\"PG-13\"`, `\"R\"`: These columns are dummy variables of the rating of the movie. It takes the value 1 if the move is rated as the column name and 0 otherwise. For your convinience, the reference dummy has already been dropped."]},{"cell_type":"code","execution_count":50,"id":"a7ede566-910a-445c-b11a-68d192ac8506","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1732294579524,"lastExecutedByKernel":"48c257de-1f0f-4f7c-904a-b9679d4daabe","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\n# Import any additional modules and start coding below\ndf = pd.read_csv(\"rental_info.csv\")\nprint(df.columns)","outputsMetadata":{"0":{"height":101,"type":"stream"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","from sklearn.preprocessing import StandardScaler\n","from torch.utils.data import DataLoader,TensorDataset"]},{"cell_type":"code","execution_count":51,"id":"ac918bfe-2536-479f-9df9-9d4fcd6d4802","metadata":{"executionCancelledAt":null,"executionTime":85,"lastExecutedAt":1732295473866,"lastExecutedByKernel":"48c257de-1f0f-4f7c-904a-b9679d4daabe","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import any additional modules and start coding below\ndf = pd.read_csv(\"rental_info.csv\")\n\n\n# Convert the 'return_date' and 'rental_date' columns to datetime format\ndf[\"return_date\"] = pd.to_datetime(df[\"return_date\"])\ndf[\"rental_date\"] = pd.to_datetime(df[\"rental_date\"])\n\n# Calculate the rental length in days\ndf[\"rental_length_days\"] = (df[\"return_date\"] - df[\"rental_date\"]).dt.days\n\n\n\n# Create dummy columns based on the values in 'special_features'\ndf[\"deleted_scenes\"] = df[\"special_features\"].apply(lambda x: 1 if \"Deleted Scenes\" in str(x) else 0)\ndf[\"behind_the_scenes\"] = df[\"special_features\"].apply(lambda x: 1 if \"Behind the Scenes\" in str(x) else 0)\ndf[\"trailers\"] = df[\"special_features\"].apply(lambda x: 1 if \"Trailers\" in str(x) else 0)\ndf[\"commentaries\"] = df[\"special_features\"].apply(lambda x: 1 if \"Commentaries\" in str(x) else 0)\n\ndf.drop([\"return_date\",\"rental_date\",\"special_features\"],axis = 1,inplace = True)\n\nY = df[[\"rental_length_days\"]]\nX = df.drop(\"rental_length_days\", axis = 1)\n","outputsMetadata":{"0":{"height":508,"type":"stream"}}},"outputs":[],"source":["# Load the dataset\n","df = pd.read_csv(\"rental_info.csv\")  # Load the dataset containing rental information\n","\n","# Convert the 'return_date' and 'rental_date' columns to datetime format\n","df[\"return_date\"] = pd.to_datetime(df[\"return_date\"])  # Convert return_date to datetime\n","df[\"rental_date\"] = pd.to_datetime(df[\"rental_date\"])  # Convert rental_date to datetime\n","\n","# Calculate the rental length in days\n","df[\"rental_length_days\"] = (df[\"return_date\"] - df[\"rental_date\"]).dt.days  # Subtract dates to get rental length\n","\n","# Create dummy columns based on the values in 'special_features'\n","df[\"deleted_scenes\"] = df[\"special_features\"].apply(lambda x: 1 if \"Deleted Scenes\" in str(x) else 0)  # Mark if Deleted Scenes exists\n","df[\"behind_the_scenes\"] = df[\"special_features\"].apply(lambda x: 1 if \"Behind the Scenes\" in str(x) else 0)  # Mark if Behind the Scenes exists\n","df[\"trailers\"] = df[\"special_features\"].apply(lambda x: 1 if \"Trailers\" in str(x) else 0)  # Mark if Trailers exists\n","df[\"commentaries\"] = df[\"special_features\"].apply(lambda x: 1 if \"Commentaries\" in str(x) else 0)  # Mark if Commentaries exists\n","\n","# Drop unnecessary columns\n","df.drop([\"return_date\", \"rental_date\", \"special_features\"], axis=1, inplace=True)  # Remove columns no longer needed\n","\n","# Define target variable (Y) and feature variables (X)\n","Y = df[[\"rental_length_days\"]]  # Target variable: rental length in days\n","X = df.drop(\"rental_length_days\", axis=1)  # Feature variables"]},{"cell_type":"code","execution_count":52,"id":"ad4c758c-66e7-45df-b3e1-6b2ed4637cb8","metadata":{},"outputs":[],"source":["# Split the dataset into training and testing sets\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8, random_state=9)  # 80% training, 20% testing\n","\n","# Standardize the training features\n","scaler_train = StandardScaler()  # Initialize a StandardScaler\n","X_train_scale = torch.tensor(scaler_train.fit_transform(X_train), dtype=torch.float)  # Scale and convert to PyTorch tensor\n","Y_train = torch.tensor(Y_train.values, dtype=torch.float)  # Convert target to PyTorch tensor\n","\n","# Standardize the testing features\n","scaler_test = StandardScaler()  # Initialize a StandardScaler for test set\n","X_test_scale = torch.tensor(scaler_test.fit_transform(X_test), dtype=torch.float)  # Scale and convert to PyTorch tensor\n","Y_test = torch.tensor(Y_test.values, dtype=torch.float)  # Convert target to PyTorch tensor\n","\n","# Create DataLoader objects for training and testing\n","dataset_train = TensorDataset(X_train_scale, Y_train)  # Combine features and target into a dataset\n","dataloader_train = DataLoader(dataset_train, batch_size=10, shuffle=True)  # DataLoader for training\n","\n","dataset_test = TensorDataset(X_test_scale, Y_test)  # Combine features and target into a dataset\n","dataloader_test = DataLoader(dataset_test, batch_size=10, shuffle=False)  # DataLoader for testing"]},{"cell_type":"code","execution_count":55,"id":"7989bc92","metadata":{},"outputs":[{"data":{"text/plain":["MultiLayerNN(\n","  (relu): ReLU()\n","  (fc1): Linear(in_features=16, out_features=256, bias=True)\n","  (fc2): Linear(in_features=256, out_features=256, bias=True)\n","  (fc3): Linear(in_features=256, out_features=1, bias=True)\n",")"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["# Define the Multi-Layer Neural Network\n","class MultiLayerNN(nn.Module):\n","    def __init__(self, in_dim, hidden_dim, out_dim):\n","        super().__init__()\n","        self.relu = nn.ReLU()  # ReLU activation function\n","        self.fc1 = nn.Linear(in_dim, hidden_dim)  # First hidden layer\n","        self.fc2 = nn.Linear(hidden_dim, hidden_dim)  # Second hidden layer\n","        self.fc3 = nn.Linear(hidden_dim, out_dim)  # Output layer\n","    \n","    def forward(self, x):\n","        # Forward pass through the network\n","        x = self.relu(self.fc1(x))  # First hidden layer\n","        x = self.relu(self.fc2(x))  # Second hidden layer\n","        x = self.fc3(x)  # Output layer (no activation for regression)\n","        return x\n","\n","# Initialize model, loss function, and optimizer\n","learning_rate = 0.01  # Learning rate for optimizer\n","epochs = 1000  # Number of training epochs\n","model = MultiLayerNN(X_train_scale.shape[1], 256, 1)  # Initialize the model with input, hidden, and output dimensions\n","criterion = nn.MSELoss()  # Mean Squared Error Loss for regression\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  # Stochastic Gradient Descent optimizer\n","model.train()  # Set model to training mode"]},{"cell_type":"code","execution_count":56,"id":"be39d6c1","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training loss of Epoch 50: 1.5728729182077825\n","Training loss of Epoch 100: 1.5014666848007951\n","Training loss of Epoch 150: 1.4636295957533367\n","Training loss of Epoch 200: 1.4491577288818416\n","Training loss of Epoch 250: 1.4395851522707581\n","Training loss of Epoch 300: 1.4315606250865802\n","Training loss of Epoch 350: 1.423676493208506\n","Training loss of Epoch 400: 1.4175708467291979\n","Training loss of Epoch 450: 1.4134946766862069\n","Training loss of Epoch 500: 1.4106774448679131\n","Training loss of Epoch 550: 1.4045877663449475\n","Training loss of Epoch 600: 1.4028247452691092\n","Training loss of Epoch 650: 1.4021198511699038\n","Training loss of Epoch 700: 1.3991649419955845\n","Training loss of Epoch 750: 1.3997845344122137\n","Training loss of Epoch 800: 1.3979827886707112\n","Training loss of Epoch 850: 1.3972070839305955\n","Training loss of Epoch 900: 1.3946481414779235\n","Training loss of Epoch 950: 1.3938441402722852\n","Training loss of Epoch 1000: 1.393873757906581\n"]}],"source":["# Training loop\n","for epoch in range(epochs):\n","    training_losses = []  # Track loss for each epoch\n","    for batch in dataloader_train:\n","        x, y = batch[0], batch[1]  # Extract features and target from batch\n","        optimizer.zero_grad()  # Reset gradients\n","        pred = model(x)  # Forward pass\n","        loss = criterion(pred, y)  # Compute loss\n","        loss.backward()  # Backpropagation\n","        optimizer.step()  # Update weights\n","        training_losses.append(loss.item())  # Store loss for the epoch\n","    if (epoch + 1) % 50 == 0:  # Print loss every 50 epochs\n","        print(f\"Training loss of Epoch {epoch + 1}: {np.mean(training_losses)}\")"]},{"cell_type":"code","execution_count":48,"id":"a647b6a5","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1.3491306\n"]}],"source":["# Evaluate model on training data\n","with torch.no_grad():  # No gradient calculation during evaluation\n","    y_true = []  # Store true values\n","    y_pred = []  # Store predicted values\n","    model.eval()  # Set model to evaluation mode\n","    for batch in dataloader_train:\n","        x, y = batch[0], batch[1]\n","        pred = model(x)  # Forward pass\n","        y_true.extend(y.numpy())  # Append true values\n","        y_pred.extend(pred.numpy())  # Append predicted values\n","\n","y_true = np.array(y_true)  # Convert to numpy array\n","y_pred = np.array(y_pred)  # Convert to numpy array\n","mse = mean_squared_error(y_true, y_pred)  # Compute Mean Squared Error\n","print(f\"Training MSE: {mse}\")"]},{"cell_type":"code","execution_count":47,"id":"86997f9b","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1.8955426\n"]}],"source":["# Evaluate model on testing data\n","with torch.no_grad():\n","    y_true = []  # Store true values\n","    y_pred = []  # Store predicted values\n","    model.eval()\n","    for batch in dataloader_test:\n","        x, y = batch[0], batch[1]\n","        pred = model(x)  # Forward pass\n","        y_true.extend(y.numpy())  # Append true values\n","        y_pred.extend(pred.numpy())  # Append predicted values\n","\n","y_true = np.array(y_true)  # Convert to numpy array\n","y_pred = np.array(y_pred)  # Convert to numpy array\n","mse = mean_squared_error(y_true, y_pred)  # Compute Mean Squared Error\n","print(f\"Testing MSE: {mse}\")"]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":5}
